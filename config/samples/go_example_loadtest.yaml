apiVersion: e2etest.grpc.io/v1
kind: LoadTest
metadata:
  # Every load test instance must be assigned a unique name on the
  # cluster. There are ways we can circumvent naming clashes, such
  # as using namespaces or dynamically assigning names.
  name: go-example

  # As a custom resource, it behaves like a native kubernetes object.
  # This means that users can perform CRUD operations through the
  # Kubernetes API or kubectl. In addition, it means that the user
  # can set any metadata on it.
  labels:
    language: go
spec:
  # The user can specify servers to use when running tests. The
  # initial version only supports 1 server to limit scope. Servers
  # is an array for future expansion.
  #
  # There are many designs and systems to pursue load balancing,
  # organizing and monitoring a mesh of servers. Therefore, this
  # will likely be expanded in the future.
  servers:
    - language: go
      clone:
        repo: https://github.com/grpc/grpc-go.git
        gitRef: master
      build:
        command: ["go"]
        args: ["build", "-o", "/src/workspace/bin/worker", "./benchmark/worker"]
      run:
        command: ["/src/workspace/bin/worker"]

  # Users can specify multiple clients. They are bound by the
  # number of nodes.
  clients:
    - language: go
      clone:
        repo: https://github.com/grpc/grpc-go.git
        gitRef: master
      build:
        command: ["go"]
        args: ["build", "-o", "/src/workspace/bin/worker", "./benchmark/worker"]
      run:
        command: ["/src/workspace/bin/worker"]

  # We can optionally specify where to place the results. The
  # controller will attempt to mount a service account in the driver.
  # This can be used for uploading results to GCS or BigQuery.
  # results:
  #   bigQueryTable: "example-project.foo.demo_dataset"

  # ScenariosJSON is string with the contents of a Scenarios message, formatted
  # as JSON. See the Scenarios protobuf definition for details:
  # https://github.com/grpc/grpc-proto/blob/master/grpc/testing/control.proto.
  scenariosJSON: |
    {
      "scenarios": [
        {
          "name": "go_example_scenario",
          "warmup_seconds": 5,
          "benchmark_seconds": 30,
          "num_servers": 1,
          "server_config": {
            "async_server_threads": 1,
            "channel_args": [
              {
                "str_value": "latency",
                "name": "grpc.optimization_target"
              }
            ],
            "server_type": "ASYNC_GENERIC_SERVER",
            "payload_config": {
              "bytebuf_params": {
                "resp_size": 0,
                "req_size": 0
              }
            },
            "security_params": null,
            "threads_per_cq": 0,
            "server_processes": 0
          },
          "client_config": {
            "security_params": null,
            "channel_args": [
              {
                "str_value": "latency",
                "name": "grpc.optimization_target"
              }
            ],
            "async_client_threads": 1,
            "outstanding_rpcs_per_channel": 1,
            "rpc_type": "STREAMING",
            "payload_config": {
              "bytebuf_params": {
                "resp_size": 0,
                "req_size": 0
              }
            },
            "client_channels": 1,
            "threads_per_cq": 0,
            "load_params": {
              "closed_loop": {}
            },
            "client_type": "SYNC_CLIENT",
            "histogram_params": {
              "max_possible": 60000000000,
              "resolution": 0.01
            },
            "client_processes": 0
          },
          "num_clients": 1
        }
      ]
    }

